{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df871cc9-9636-4978-8672-28e34728bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fill_account_turnover_f import fill_account_turnover_f\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "import time\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b2f214-d833-4fda-9e96-216ceca80dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"fill_account_turnover_f\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql('Use DM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74aea92-cc99-4cf0-a781-ebf4a12c3055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-01-2018', '02-01-2018', '03-01-2018', '04-01-2018', '05-01-2018', '06-01-2018', '07-01-2018', '08-01-2018', '09-01-2018', '10-01-2018', '11-01-2018', '12-01-2018', '13-01-2018', '14-01-2018', '15-01-2018', '16-01-2018', '17-01-2018', '18-01-2018', '19-01-2018', '20-01-2018', '21-01-2018', '22-01-2018', '23-01-2018', '24-01-2018', '25-01-2018', '26-01-2018', '27-01-2018', '28-01-2018', '29-01-2018', '30-01-2018', '31-01-2018']\n"
     ]
    }
   ],
   "source": [
    "dates_jan_2018 = [f\"{day:02d}-01-2018\" for day in range(1, 32)]\n",
    "print(dates_jan_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0274e84-2e10-4257-8c66-5853fb6aa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "job_name = \"fill_dm_account_turnover_f\"\n",
    "status = \"SUCCESS\"\n",
    "for date_str in dates_jan_2018:\n",
    "    df = fill_account_turnover_f(date_str, spark)\n",
    "    df.write \\\n",
    "      .mode(\"append\") \\\n",
    "      .partitionBy(\"on_date\") \\\n",
    "      .format(\"parquet\") \\\n",
    "      .saveAsTable(\"DM.DM_ACCOUNT_TURNOVER_F\")\n",
    "\n",
    "time.sleep(5)\n",
    "end_time = datetime.now()\n",
    "log_row = Row(\n",
    "    id=str(uuid.uuid4()),\n",
    "    job_name=job_name,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    status=status\n",
    ")\n",
    "log_df = spark.createDataFrame([log_row])\n",
    "log_df.write.mode(\"append\").insertInto(\"logs.LOGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595ac5e5-e62c-400b-919d-2e825c4532c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c108423-d753-463a-84fb-112828536f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
