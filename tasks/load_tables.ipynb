{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8317f7-ccb6-424a-a17b-d24f3db78d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETLProcess\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1510b4f-7d28-4417-9205-fd805fe4f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_with_logging(table_name: str, csv_path: str, current_max_id: int):\n",
    "    start_time = datetime.now()\n",
    "    job_name = f\"load_{table_name}\"\n",
    "    status = \"SUCCESS\"\n",
    "\n",
    "    try:\n",
    "        df = spark.read.csv(csv_path, sep=';', header=True, inferSchema=True)\n",
    "        df.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "    except Exception as e:\n",
    "        status = \"FAILURE\"\n",
    "        print(f\"Error loading {table_name}: {e}\")\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    new_id = current_max_id + 1\n",
    "\n",
    "    log_row = Row(\n",
    "        id=new_id,\n",
    "        job_name=job_name,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        status=status\n",
    "    )\n",
    "    log_df = spark.createDataFrame([log_row])\n",
    "    log_df.write.mode(\"append\").insertInto(\"DS.LOGS\")\n",
    "\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec26aca4-f711-4d0c-8295-32b21b1eb74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ==== Получение текущего максимального ID ====\n",
    "try:\n",
    "    current_max = spark.table(\"DS.LOGS\").agg(spark_max(\"id\")).collect()[0][0]\n",
    "    current_max = current_max if current_max is not None else 0\n",
    "except:\n",
    "    current_max = 0\n",
    "print(current_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c127af5-65af-4e8a-96a3-2a291fb968d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_load = [\n",
    "    (\"DS.FT_BALANCE_F\", \"/data/ft_balance_f.csv\"),\n",
    "    (\"DS.FT_POSTING_F\", \"/data/ft_posting_f.csv\"),\n",
    "    (\"DS.MD_ACCOUNT_D\", \"/data/md_account_d.csv\"),\n",
    "    (\"DS.MD_CURRENCY_D\", \"/data/md_currency_d.csv\"),\n",
    "    (\"DS.MD_EXCHANGE_RATE_D\", \"/data/md_exchange_rate_d.csv\"),\n",
    "    (\"DS.MD_LEDGER_ACCOUNT_S\", \"/data/md_ledger_account_s.csv\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1552c3b-bc7f-47ce-ae79-03e7d54efc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_name, csv_path in tables_to_load:\n",
    "    current_max = load_table_with_logging(job_name, csv_path, current_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c5842a-2387-4323-86ac-e594ec8433e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------+--------------------------+--------------------------+-------+\n",
      "|id |job_name                   |start_time                |end_time                  |status |\n",
      "+---+---------------------------+--------------------------+--------------------------+-------+\n",
      "|3  |load_DS.MD_ACCOUNT_D       |2025-07-02 18:45:46.823517|2025-07-02 18:45:53.158756|SUCCESS|\n",
      "|1  |load_DS.FT_BALANCE_F       |2025-07-02 18:45:27.423546|2025-07-02 18:45:37.145171|SUCCESS|\n",
      "|1  |load_ft_balance_f.csv      |2025-07-02 17:54:00.497638|2025-07-02 17:54:06.09876 |SUCCESS|\n",
      "|5  |load_DS.MD_EXCHANGE_RATE_D |2025-07-02 18:46:01.195983|2025-07-02 18:46:07.217475|SUCCESS|\n",
      "|6  |load_DS.MD_LEDGER_ACCOUNT_S|2025-07-02 18:46:07.781244|2025-07-02 18:46:13.775723|SUCCESS|\n",
      "|2  |load_DS.FT_POSTING_F       |2025-07-02 18:45:39.34216 |2025-07-02 18:45:45.694027|SUCCESS|\n",
      "|4  |load_DS.MD_CURRENCY_D      |2025-07-02 18:45:54.173007|2025-07-02 18:46:00.196014|SUCCESS|\n",
      "+---+---------------------------+--------------------------+--------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM DS.LOGS\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5059d-c9bd-4331-b263-b8e2c3b0ca47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
